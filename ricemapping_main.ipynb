{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise \n",
    "ee.Initialize()\n",
    "# Configure the pretty printing output & initialize earthengine\n",
    "pp = pprint.PrettyPrinter(depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add year attribute to image\n",
    "def addyear(img):\n",
    "    return img.set('year', ee.Image(img).date().get('year'))\n",
    "\n",
    "# Function to add Day Of Year attribute to image\n",
    "def addDOY(img):\n",
    "    return img.set('DOY', ee.Image(img).date().getRelative('day', 'year'))\n",
    "\n",
    "# Function to full date\n",
    "def addDATE(img):\n",
    "    return ee.Image.constant(img.date().getRelative('day', 'year')).int().updateMask(img.select(0).mask())\n",
    "\n",
    "\n",
    "# Parameters for masking function (move to preamble)\n",
    "def landsatmasking(img):\n",
    "\n",
    "  qa = img.select('pixel_qa')\n",
    "  # If the cloud bit (5) is set and the cloud confidence (7) is high\n",
    "  # or the cloud shadow bit is set (3), then it's a bad pixel.\n",
    "  cloudorsnow = qa.bitwiseAnd(1 << 5). \\\n",
    "    And(qa.bitwiseAnd(1 << 7)). \\\n",
    "    Or(qa.bitwiseAnd(1 << 3)). \\\n",
    "    Or(qa.bitwiseAnd(1 << 4))  \n",
    "  # Remove edge pixels that don't occur in all bands\n",
    "  mask2 = img.mask().reduce(ee.Reducer.min())\n",
    "  return img.updateMask(cloudorsnow.Not()).updateMask(mask2)\n",
    "\n",
    "# Spectral indices function: adds index as a new band to every image\n",
    "def addINDICES(img):\n",
    "    \n",
    "    ndvi = img.normalizedDifference(['B4', 'B3']).rename('NDVI')\n",
    "    lswi = img.normalizedDifference(['B4', 'B5']).rename('LSWI')\n",
    "    ndsi = img.normalizedDifference(['B2', 'B5']).rename('NDSI')    \n",
    "    # I multiply by scale factor for EVI (DIDNT WORK TO SOLVE HIGH VALUES ISSUE)\n",
    "    evi = img.expression(\n",
    "    '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "        'NIR': img.select('B4').multiply(0.0001),\n",
    "      'RED': img.select('B3').multiply(0.0001),\n",
    "      'BLUE': img.select('B1').multiply(0.0001)\n",
    "    }).rename('EVI')\n",
    "    \n",
    "    return img.addBands(ndvi).addBands(lswi).addBands(ndsi).addBands(evi)\n",
    "\n",
    "# Function to add a band of rice classification to each image in the col\n",
    "# Rule for rice is that LSWI − NDVI > 0 or LSWI − EVI > 0\n",
    "def addRICE(img):    \n",
    "    rice = img.expression(\n",
    "    \"(lswi - ndvi > 0) || (lswi - evi > 0) ? 1\\\n",
    "    :2\",{'lswi': img.select('LSWI'),'ndvi': img.select('NDVI'),'evi': img.select('EVI')}).rename('RICE')\n",
    "    \n",
    "    return img.addBands(rice)\n",
    "\n",
    "# Apply Masks Function\n",
    "def landcovermasking(img):\n",
    "  return img.updateMask(mask1.Not()).updateMask(mask2.Not()).updateMask(mask3.unmask().Not()).updateMask(mask4.Not())\n",
    "\n",
    "# Function to create binary layer for rice class\n",
    "def classornot(img):\n",
    "    return img.eq(1)\n",
    "\n",
    "# Percentile calculator\n",
    "def percentileextract(datedif):\n",
    "    if datedif < 43 :\n",
    "        percentile = 70\n",
    "    elif datedif > 70 :\n",
    "        percentile = 90\n",
    "    else :\n",
    "        percentile = 80\n",
    "    return percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INPUTS AND TABLE LOADING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out Directory\n",
    "maps_outdir = os.path.join(os.path.expanduser('~'), '../rice-mapping-japan/results/maps')\n",
    "\n",
    "# Map type: binary or representing rice types (normal, early, second transplants'\n",
    "# 'yes' for binary, 'no' for maps with different types\n",
    "# If not binary, map values are: 1: normal rice; 10: early; 20: second; other values are combinations of those (rice detected in different periods)\n",
    "binarymap = 'yes'  \n",
    "\n",
    "# Define periods names\n",
    "periodnames = {'8589','9094','9599','0004','0509','1014','1519'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Japan Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecd529d829d4330976b1f30da8696ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[38, 138], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(To…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map(center=[38,138], zoom=6)\n",
    "Map.add_basemap('HYBRID')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load prefectures shapefile and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Japan shp is not small, so we ingest it from personal account (otherwise we can upload locally with geemap.shp_to_ee)\n",
    "japan_shp = 'users/luiscartor/japan_gadm0'\n",
    "japan = geemap.ee.FeatureCollection(japan_shp)\n",
    "\n",
    "point = ee.Geometry.Point([38,138])\n",
    "Map.addLayer(point, {}, 'Point')\n",
    "\n",
    "# Load prefecture shapefile (from GEE account)\n",
    "prefs_shp = 'users/luiscartor/japan_gadm1_noOKINAWA'\n",
    "prefs = geemap.ee.FeatureCollection(prefs_shp)\n",
    "\n",
    "Map.addLayer(prefs, {}, 'Prefectures')\n",
    "\n",
    "# Can use this block as playground visualize auxiliary data layers (e.g. masks) created later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transplanting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prefecture</th>\n",
       "      <th>8589</th>\n",
       "      <th>9094</th>\n",
       "      <th>9599</th>\n",
       "      <th>0004</th>\n",
       "      <th>0509</th>\n",
       "      <th>1014</th>\n",
       "      <th>1519</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hokkaido</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>142</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aomori</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iwate</td>\n",
       "      <td>128</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>132</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miyagi</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akita</td>\n",
       "      <td>134</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>136</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prefecture  8589  9094  9599  0004  0509  1014  1519\n",
       "0   Hokkaido   142   142   142   140   140   142   139\n",
       "1     Aomori   134   134   133   132   135   136   135\n",
       "2      Iwate   128   130   130   130   130   132   130\n",
       "3     Miyagi   123   124   123   123   124   125   124\n",
       "4      Akita   134   133   133   133   133   136   135"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of prefectures transplanting START DOY\n",
    "# These data can be found in Carrasco et al 2022 (In prep.)\n",
    "transplant_startdates_table = '../rice-mapping-japan/data/transplanting_startdates.csv'\n",
    "transplant_startdates = pd.read_csv(transplant_startdates_table, sep=\",\")\n",
    "transplant_startdates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prefecture</th>\n",
       "      <th>8589</th>\n",
       "      <th>9094</th>\n",
       "      <th>9599</th>\n",
       "      <th>0004</th>\n",
       "      <th>0509</th>\n",
       "      <th>1014</th>\n",
       "      <th>1519</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hokkaido</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>142</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aomori</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iwate</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>132</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miyagi</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akita</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>136</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prefecture  8589  9094  9599  0004  0509  1014  1519\n",
       "0   Hokkaido   142   142   142   140   140   142   139\n",
       "1     Aomori   134   134   133   132   135   136   135\n",
       "2      Iwate   130   130   130   130   130   132   130\n",
       "3     Miyagi   124   124   123   123   124   125   124\n",
       "4      Akita   133   133   133   133   133   136   135"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Due to data inconsistencies between years, we use starting dates from 9094 for 8589\n",
    "transplant_startdates['8589'] = transplant_startdates['9094']\n",
    "transplant_startdates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prefecture</th>\n",
       "      <th>8589</th>\n",
       "      <th>9094</th>\n",
       "      <th>9599</th>\n",
       "      <th>0004</th>\n",
       "      <th>0509</th>\n",
       "      <th>1014</th>\n",
       "      <th>1519</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hokkaido</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aomori</td>\n",
       "      <td>144</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "      <td>146</td>\n",
       "      <td>149</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iwate</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>142</td>\n",
       "      <td>145</td>\n",
       "      <td>147</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miyagi</td>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akita</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prefecture  8589  9094  9599  0004  0509  1014  1519\n",
       "0   Hokkaido   151   151   151   149   150   153   150\n",
       "1     Aomori   144   143   144   145   146   149   148\n",
       "2      Iwate   142   143   144   142   145   147   145\n",
       "3     Miyagi   133   134   135   134   139   143   142\n",
       "4      Akita   143   144   144   145   145   150   150"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of prefectures transplanting START DOY\n",
    "# This data can be found in Carrasco et al 2022 (In prep.)\n",
    "transplant_enddates_table = '../rice-mapping-japan/data/transplanting_enddates.csv'\n",
    "transplant_enddates = pd.read_csv(transplant_enddates_table, sep=\",\")\n",
    "transplant_enddates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prefecture</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hokkaido</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aomori</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iwate</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miyagi</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akita</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prefecture  difference\n",
       "0   Hokkaido          39\n",
       "1     Aomori          40\n",
       "2      Iwate          42\n",
       "3     Miyagi          39\n",
       "4      Akita          40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trasplanting period lenghts\n",
    "transplantdates_differences = pd.DataFrame({'Prefecture':transplant_enddates['Prefecture'],'difference':transplant_enddates['8589']+30 - transplant_startdates['8589']})\n",
    "transplantdates_differences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Prefecture  8589  9094  9599  0004  0509  1014  1519\n",
      "0      Kochi   102    97    95    94    94    94    93\n",
      "1   Kumamoto   101    98   100   100   100   100   100\n",
      "2   Miyazaki    91    85    82    80    80    80    79\n",
      "3  Kagoshima    93    86    84    82    85    85    78\n",
      "  Prefecture  8589  9094  9599  0004  0509  1014  1519\n",
      "0      Kochi   120   119   117   114   112   112   112\n",
      "1   Kumamoto   114   112   113   113   113   113   113\n",
      "2   Miyazaki   105    99    97    95    95    97    96\n",
      "3  Kagoshima   107   105   102   100   102   105   106\n",
      "  Prefecture  8589  9094  9599  0004  0509  1014  1519\n",
      "0      Kochi   218   218   218   218   218   218   218\n",
      "1  Kagoshima   215   215   215   215   215   215   215\n",
      "  Prefecture  8589  9094  9599  0004  0509  1014  1519\n",
      "0      Kochi   228   228   228   228   228   228   228\n",
      "1  Kagoshima   230   230   230   230   230   230   230\n"
     ]
    }
   ],
   "source": [
    "# Some prefectures have \"early\" or \"second\" transplantations\n",
    "# Here we load the dates of those especial transplantation periods\n",
    "# These data can be found in Carrasco et al 2022 (In prep.)\n",
    "earlytransplant_startdates_table = '../rice-mapping-japan/data/earlytransplanting_startdates.csv'\n",
    "earlytransplant_startdates = pd.read_csv(earlytransplant_startdates_table, sep=\",\")\n",
    "earlytransplant_enddates_table = '../rice-mapping-japan/data/earlytransplanting_enddates.csv'\n",
    "earlytransplant_enddates = pd.read_csv(earlytransplant_enddates_table, sep=\",\")\n",
    "\n",
    "secondtransplant_startdates_table = '../rice-mapping-japan/data/secondtransplanting_startdates.csv'\n",
    "secondtransplant_startdates = pd.read_csv(secondtransplant_startdates_table, sep=\",\")\n",
    "secondtransplant_enddates_table = '../rice-mapping-japan/data/secondtransplanting_enddates.csv'\n",
    "secondtransplant_enddates = pd.read_csv(secondtransplant_enddates_table, sep=\",\")\n",
    "\n",
    "print(earlytransplant_startdates)\n",
    "print(earlytransplant_enddates)\n",
    "print(secondtransplant_startdates)\n",
    "print(secondtransplant_enddates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prefecture</th>\n",
       "      <th>Meteostation</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "      <th>360</th>\n",
       "      <th>361</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hokkaido</td>\n",
       "      <td>Sapporo</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>-5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aomori</td>\n",
       "      <td>Aomori</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>-2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iwate</td>\n",
       "      <td>Morioka</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miyagi</td>\n",
       "      <td>Sendai</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akita</td>\n",
       "      <td>Akita</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prefecture Meteostation    1    2    3    4    5    6    7    8  ...  356  \\\n",
       "0   Hokkaido      Sapporo -5.8 -5.9 -6.0 -6.1 -6.3 -6.4 -6.5 -6.6  ... -5.0   \n",
       "1     Aomori       Aomori -2.8 -2.9 -3.0 -3.1 -3.2 -3.3 -3.3 -3.4  ... -2.1   \n",
       "2      Iwate      Morioka -4.2 -4.4 -4.5 -4.6 -4.7 -4.9 -5.0 -5.1  ... -3.2   \n",
       "3     Miyagi       Sendai -0.7 -0.8 -0.9 -1.0 -1.1 -1.2 -1.2 -1.3  ...  0.2   \n",
       "4      Akita        Akita -1.4 -1.5 -1.6 -1.7 -1.8 -1.9 -2.0 -2.1  ... -0.7   \n",
       "\n",
       "   357  358  359  360  361  362  363  364  365  \n",
       "0 -5.0 -5.1 -5.1 -5.2 -5.3 -5.4 -5.5 -5.6 -5.7  \n",
       "1 -2.2 -2.2 -2.3 -2.3 -2.4 -2.5 -2.5 -2.6 -2.7  \n",
       "2 -3.3 -3.4 -3.4 -3.5 -3.6 -3.7 -3.8 -4.0 -4.1  \n",
       "3  0.2  0.1  0.0 -0.1 -0.2 -0.3 -0.4 -0.5 -0.6  \n",
       "4 -0.7 -0.8 -0.8 -0.9 -1.0 -1.0 -1.1 -1.2 -1.3  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of prefectures with DOY per temperature data\n",
    "# These data can be found in Carrasco et al 2022 (In prep.)\n",
    "temperature_table = '../rice-mapping-japan/data/prefectureDOYmintemp.csv'\n",
    "tempdata = pd.read_csv(temperature_table, sep=\",\")\n",
    "tempdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates table with DOY with first/last 0/5/10 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prefecture</th>\n",
       "      <th>TGS0S</th>\n",
       "      <th>TGS0E</th>\n",
       "      <th>TGS5S</th>\n",
       "      <th>TGS5E</th>\n",
       "      <th>TGS10S</th>\n",
       "      <th>TGS10E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hokkaido</td>\n",
       "      <td>90</td>\n",
       "      <td>327</td>\n",
       "      <td>115</td>\n",
       "      <td>302</td>\n",
       "      <td>148</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aomori</td>\n",
       "      <td>85</td>\n",
       "      <td>339</td>\n",
       "      <td>113</td>\n",
       "      <td>310</td>\n",
       "      <td>144</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iwate</td>\n",
       "      <td>90</td>\n",
       "      <td>329</td>\n",
       "      <td>116</td>\n",
       "      <td>299</td>\n",
       "      <td>146</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miyagi</td>\n",
       "      <td>68</td>\n",
       "      <td>360</td>\n",
       "      <td>99</td>\n",
       "      <td>321</td>\n",
       "      <td>128</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akita</td>\n",
       "      <td>75</td>\n",
       "      <td>349</td>\n",
       "      <td>104</td>\n",
       "      <td>316</td>\n",
       "      <td>133</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prefecture  TGS0S  TGS0E  TGS5S  TGS5E  TGS10S  TGS10E\n",
       "0   Hokkaido     90    327    115    302     148     278\n",
       "1     Aomori     85    339    113    310     144     283\n",
       "2      Iwate     90    329    116    299     146     278\n",
       "3     Miyagi     68    360     99    321     128     295\n",
       "4      Akita     75    349    104    316     133     289"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectors to store TGS values (first day of certain min temperature)\n",
    "TGS0S = []; TGS0E = []; TGS5S = []; TGS5E = []; TGS10S = []; TGS10E = [];\n",
    "\n",
    "\n",
    "# We loop through each prefecture\n",
    "for i in range(len(tempdata)):\n",
    "    #print(i)\n",
    "#i = 0\n",
    "\n",
    "    # Extracts first DOY with mintemp > 0,5,10\n",
    "    T0S = next(x for x, val in enumerate(tempdata.iloc[i,2:]) if val > 0)\n",
    "    T5S = next(x for x, val in enumerate(tempdata.iloc[i,2:]) if val > 5)\n",
    "    T10S = next(x for x, val in enumerate(tempdata.iloc[i,2:]) if val > 10)\n",
    "\n",
    "    # Extracts first DOY with mintemp < 0,5,10 after summer (we consider temp values since August (DOY=214))\n",
    "    # If value does not exist (desired temp falls into next year), we set to last day of year (so to not to use following year image)\n",
    "    T0E = next((x for x, val in enumerate(tempdata.iloc[i,215:]) if val < 0), 365-214) + 214\n",
    "    T5E = next((x for x, val in enumerate(tempdata.iloc[i,215:]) if val < 5), 365-214) + 214\n",
    "    T10E = next((x for x, val in enumerate(tempdata.iloc[i,215:]) if val < 10), 365-214) + 214\n",
    "\n",
    "    TGS0S.append(T0S); TGS5S.append(T5S); TGS10S.append(T10S); TGS0E.append(T0E); TGS5E.append(T5E); TGS10E.append(T10E); \n",
    "\n",
    "tgstable = pd.DataFrame({'Prefecture': tempdata['Prefecture'], 'TGS0S': TGS0S, 'TGS0E': TGS0E, 'TGS5S': TGS5S\n",
    "                        , 'TGS5E': TGS5E, 'TGS10S': TGS10S, 'TGS10E': TGS10E})\n",
    "tgstable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-37567713f0f6>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  tgstable['TGS5S'][45] = 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prefecture    Kagoshima\n",
       "TGS0S                 0\n",
       "TGS0E               365\n",
       "TGS5S                40\n",
       "TGS5E               365\n",
       "TGS10S               86\n",
       "TGS10E              330\n",
       "Name: 45, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kagoshima gives wrong values due to the TGS5S (above 5 in January but drops later), so we mannualy edit to real value\n",
    "tgstable['TGS5S'][45] = 40\n",
    "#tgstable.loc[tgstable['Prefecture']== 'Kagoshima']['TGS5S'] = 40\n",
    "tgstable.loc[45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process datasets for masks 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mask 3: Forest (based on JAXA map)\n",
    "# Load JAXA map\n",
    "lc2015_path = 'users/luiscartor/jaxaLC2015'\n",
    "lc2015 = geemap.ee.Image(lc2015_path)\n",
    "# Select forest class\n",
    "forest = lc2015.updateMask(lc2015.gt(5)).updateMask(lc2015.lt(10)).gt(5).selfMask()\n",
    "\n",
    "\n",
    "# For mask 4: Elevation data\n",
    "# Call SRTM elevation dataset\n",
    "elevdataset = ee.Image('JAXA/ALOS/AW3D30/V2_2')\n",
    "elevation = elevdataset.select('AVE_DSM')\n",
    "# Calculate slope\n",
    "slope = ee.Terrain.slope(elevation)\n",
    "# Calculate slope > 20 deg\n",
    "slopegt3 = slope.gt(20) \n",
    "\n",
    "# Uncomment to export masks\n",
    "#geemap.ee_export_image_to_drive(forest, description='forestmask', folder='GEEexports', region=japan.geometry(), scale=30)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MAIN ROUTINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landsat 5\n",
    "L5col = ee.ImageCollection('LANDSAT/LT05/C01/T1_SR') \\\n",
    "    .select('B[1-7]','pixel_qa') \\\n",
    "    .map(addyear) \\\n",
    "    .map(addDOY)\n",
    "       \n",
    "# Landsat 7\n",
    "L7col = ee.ImageCollection('LANDSAT/LE07/C01/T1_SR') \\\n",
    "    .select('B[1-7]','pixel_qa') \\\n",
    "    .map(addyear) \\\n",
    "    .map(addDOY)\n",
    "\n",
    "# Merge collections\n",
    "L57col = L5col.merge(L7col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Year period collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to 5-year periods\n",
    "L57_8589 = L57col.filterDate('1985-01-01', '1989-12-31')\n",
    "L57_9094 = L57col.filterDate('1990-01-01', '1994-12-31')\n",
    "L57_9599 = L57col.filterDate('1995-01-01', '1999-12-31')\n",
    "L57_0004 = L57col.filterDate('2000-01-01', '2004-12-31')\n",
    "L57_0509 = L57col.filterDate('2005-01-01', '2009-12-31')\n",
    "L57_1014 = L57col.filterDate('2010-01-01', '2014-12-31')\n",
    "L57_1519 = L57col.filterDate('2015-01-01', '2019-12-31')\n",
    "\n",
    "# Creates dictionary with periods and collections\n",
    "periods_dict = {'8589': L57_8589,\n",
    "              '9094': L57_9094,\n",
    "              '9599': L57_9599,\n",
    "              '0004': L57_0004,\n",
    "              '0509': L57_0509,\n",
    "              '1014': L57_1014,\n",
    "              '1519': L57_1519}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting tambo_8589 ...\n",
      "Exporting tambo_9094 ...\n",
      "Exporting tambo_9599 ...\n",
      "Exporting tambo_0004 ...\n",
      "Exporting tambo_0509 ...\n",
      "Exporting tambo_1014 ...\n",
      "Exporting tambo_1519 ...\n"
     ]
    }
   ],
   "source": [
    "# Creates empty list for storing national rice maps for each period\n",
    "periodmapslist = list()\n",
    "\n",
    "# LOOPS THROUGH EACH PERIOD\n",
    "for periodcol in periods_dict.values():\n",
    "# INDENT from here\n",
    "\n",
    "\n",
    "# Uncomment and unindent to run for single period\n",
    "#periodcol = L57_1519\n",
    "\n",
    "    # Empty list to store prefectural maps for current loop period\n",
    "    prefmapslist = list()\n",
    "\n",
    "\n",
    "    # LOOPS THROUGH EACH PREFECTURE\n",
    "    for prefecture in transplant_startdates['Prefecture']:\n",
    "    # INDENT from here\n",
    "\n",
    "\n",
    "        # Extracts prefecture polygon\n",
    "        prefpolygon = prefs \\\n",
    "            .filter(ee.Filter.eq(\"NAME_1\", prefecture)) \n",
    "        # Clips collection to prefecture\n",
    "        prefcol = periodcol.filterBounds(prefpolygon)\n",
    "\n",
    "\n",
    "\n",
    "        # PRE-PROCESSING\n",
    "        \n",
    "        # Cloud masking\n",
    "        prefcol_masked = prefcol.map(landsatmasking)\n",
    "        \n",
    "        # Add Indices\n",
    "        prefcol_indices = prefcol_masked.map(addINDICES)\n",
    "        # Subset to spectral indices\n",
    "        prefcol_ind = prefcol_indices.select('NDVI','LSWI','NDSI','EVI')\n",
    "\n",
    "\n",
    "\n",
    "        # EXTRACTS FLOODING PERIODS\n",
    "        \n",
    "        # Flooding start day is considered the first day of transplanting (TS)\n",
    "        flood_start = int(transplant_startdates[list(periods_dict.keys())[list(periods_dict.values()).index(periodcol)]][transplant_startdates[transplant_startdates['Prefecture']==prefecture].index[0]])\n",
    "        # Flooding last day is considered the end day of transplanting + 30 days\n",
    "        flood_end = int(transplant_enddates[list(periods_dict.keys())[list(periods_dict.values()).index(periodcol)]][transplant_enddates[transplant_enddates['Prefecture']==prefecture].index[0]] + 30)\n",
    "\n",
    "        # Subset to flooding period\n",
    "        prefcol_flood = prefcol_ind.filter(ee.Filter.gte('DOY', flood_start)).filter(ee.Filter.lte('DOY', flood_end))\n",
    "\n",
    "        # Subset to non-flooding period\n",
    "        prefcol_noflood1 = prefcol_ind.filter(ee.Filter.lte('DOY', flood_start))\n",
    "        prefcol_noflood2 = prefcol_ind.filter(ee.Filter.gte('DOY', flood_end))\n",
    "        prefcol_noflood = prefcol_noflood1.merge(prefcol_noflood2)        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # EXTRACT FLOODING PERIODS FOR EARLY AND SECOND TRANSPLANTATIONS (ONLY USED FOR SOME PREFECTURES)\n",
    "        \n",
    "        # Prefectures with early transplantation periods\n",
    "        if (prefecture =='Kochi' or prefecture =='Kumamoto' or prefecture =='Miyazaki' or prefecture =='Kagoshima'): \n",
    "            earlyflood_start = int(earlytransplant_startdates[list(periods_dict.keys())[list(periods_dict.values()).index(periodcol)]][earlytransplant_startdates[earlytransplant_startdates['Prefecture']==prefecture].index[0]])\n",
    "            earlyflood_end = int(earlytransplant_enddates[list(periods_dict.keys())[list(periods_dict.values()).index(periodcol)]][earlytransplant_enddates[earlytransplant_enddates['Prefecture']==prefecture].index[0]] + 30)\n",
    "            earlyprefcol_flood = prefcol_ind.filter(ee.Filter.gte('DOY', earlyflood_start)).filter(ee.Filter.lte('DOY', earlyflood_end))\n",
    "\n",
    "        # Prefectures with second transplantation periods\n",
    "        if (prefecture =='Kochi' or prefecture =='Kagoshima'): \n",
    "            secondflood_start = int(secondtransplant_startdates[list(periods_dict.keys())[list(periods_dict.values()).index(periodcol)]][secondtransplant_startdates[secondtransplant_startdates['Prefecture']==prefecture].index[0]])\n",
    "            secondflood_end = int(secondtransplant_enddates[list(periods_dict.keys())[list(periods_dict.values()).index(periodcol)]][secondtransplant_enddates[secondtransplant_enddates['Prefecture']==prefecture].index[0]] + 30)\n",
    "            secondprefcol_flood = prefcol_ind.filter(ee.Filter.gte('DOY', earlyflood_start)).filter(ee.Filter.lte('DOY', earlyflood_end))\n",
    "\n",
    "\n",
    "        # FILTER COLLECTIONS FOR TEMPERATURE PERIODS\n",
    "        \n",
    "        # Extracting DOY for temperature data\n",
    "        TGS0S = int(tgstable['TGS0S'][tgstable[tgstable['Prefecture']==prefecture].index[0]])\n",
    "        TGS0E = int(tgstable['TGS0E'][tgstable[tgstable['Prefecture']==prefecture].index[0]]) \n",
    "        TGS5S = int(tgstable['TGS5S'][tgstable[tgstable['Prefecture']==prefecture].index[0]]) \n",
    "        TGS5E = int(tgstable['TGS5E'][tgstable[tgstable['Prefecture']==prefecture].index[0]]) \n",
    "        TGS10S = int(tgstable['TGS10S'][tgstable[tgstable['Prefecture']==prefecture].index[0]]) \n",
    "        TGS10E = int(tgstable['TGS10E'][tgstable[tgstable['Prefecture']==prefecture].index[0]])\n",
    "\n",
    "\n",
    "        # Subset to period between first 0 and last 0 min degrees:\n",
    "        L57_0S0E = prefcol_ind.filter(ee.Filter.gte('DOY', TGS0S)).filter(ee.Filter.lte('DOY', TGS0E))\n",
    "        # Subset to period between first 5 and last 5 min degrees:\n",
    "        L57_5S5E = prefcol_ind.filter(ee.Filter.gte('DOY', TGS5S)).filter(ee.Filter.lte('DOY', TGS5E))\n",
    "        # Subset to period between first 0 and first 10 min degrees:\n",
    "        L57_0S10S = prefcol_ind.filter(ee.Filter.gte('DOY', TGS0S)).filter(ee.Filter.lte('DOY', TGS10S))\n",
    "        # Subset to period between first 10 + 40days and last 10 min degrees:\n",
    "        L57_10S40to5E = prefcol_ind.filter(ee.Filter.gte('DOY', TGS10S+40)).filter(ee.Filter.lte('DOY', TGS10E))\n",
    "        # Subset to period between last 10 and first 10 (not thermal growing season)\n",
    "        L57_10E10S1 = prefcol_ind.filter(ee.Filter.lte('DOY', TGS10S))\n",
    "        L57_10E10S2 = prefcol_ind.filter(ee.Filter.gte('DOY', TGS10E))\n",
    "        L57_10E10S = L57_10E10S1.merge(L57_10E10S2)\n",
    "\n",
    "\n",
    "        # Applies function to decide percentile based on transplantation period length\n",
    "        percentile = percentileextract(flood_end-flood_start)\n",
    "        L57_flood_lswi = prefcol_flood.select('LSWI').reduce(ee.Reducer.percentile([percentile])).rename('LSWI')\n",
    "        L57_flood_ndvi = prefcol_flood.select('NDVI').median()\n",
    "        L57_flood_evi = prefcol_flood.select('EVI').median()\n",
    "\n",
    "        L57_flood = L57_flood_lswi.addBands(L57_flood_ndvi).addBands(L57_flood_evi)\n",
    "\n",
    "\n",
    "        \n",
    "        # APPLY MASKS (modified from on Dong 2016, RSE)\n",
    "\n",
    "        # Mask 1) Sparce vegetation: soil, built-up, water body, low vegetated lands. \n",
    "        L57_5S5E_max = L57_5S5E.max()\n",
    "        mask1 = L57_5S5E_max.select('EVI').lt(0.5)  \n",
    "\n",
    "        # Mask 2) Natural vegetation mask: forests, natural wetlands, grass. \n",
    "        L57_10E10S_median = L57_10E10S.median()\n",
    "        mask2 = L57_10E10S_median.select('EVI').gt(0.4) \n",
    "\n",
    "        # Mask 3) Forest mask \n",
    "        mask3 = forest\n",
    "\n",
    "        # Mask 4) Slope\n",
    "        mask4 = slopegt3\n",
    "\n",
    "        \n",
    "\n",
    "        # RICE CLASSIFICATION\n",
    "\n",
    "        # Apply masks\n",
    "        L57_flood_masked = landcovermasking(L57_flood)\n",
    "        # Classify rice\n",
    "        riceadded = addRICE(L57_flood_masked).select('RICE')\n",
    "        riceclass = classornot(riceadded)\n",
    "\n",
    "\n",
    "\n",
    "        # CLASSIFY RICE FOR PREFECTURES WITH EARLY AND SECOND PLANTATIONS\n",
    "        # Prefectures with early transplantation periods\n",
    "        if (prefecture =='Kochi' or prefecture =='Kumamoto' or prefecture =='Miyazaki' or prefecture =='Kagoshima'): \n",
    "\n",
    "            # Classify rice\n",
    "            earlypercentile = percentileextract(earlyflood_end-earlyflood_start)\n",
    "            earlyprefcol_flood_lswi = earlyprefcol_flood.select('LSWI').reduce(ee.Reducer.percentile([earlypercentile])).rename('LSWI')\n",
    "            earlyprefcol_flood_ndvi = earlyprefcol_flood.select('NDVI').median()\n",
    "            earlyprefcol_flood_evi = earlyprefcol_flood.select('EVI').median()\n",
    "            earlyprefcol_flood = earlyprefcol_flood_lswi.addBands(earlyprefcol_flood_ndvi).addBands(earlyprefcol_flood_evi)\n",
    "\n",
    "            # Apply mask\n",
    "            earlyprefcol_flood_masked = landcovermasking(earlyprefcol_flood)\n",
    "\n",
    "            # Add early rice to rice map\n",
    "            earlyrice = addRICE(earlyprefcol_flood_masked).select('RICE') \n",
    "            earlyriceclass = classornot(earlyrice).multiply(10)\n",
    "            riceclass = riceclass.add(earlyriceclass)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Prefectures with second transplantation periods\n",
    "        if (prefecture =='Kochi' or prefecture =='Kagoshima'): \n",
    "\n",
    "            # Classify rice\n",
    "            secondpercentile = percentileextract(secondflood_end-secondflood_start)\n",
    "            secondprefcol_flood_lswi = secondprefcol_flood.select('LSWI').reduce(ee.Reducer.percentile([secondpercentile])).rename('LSWI')\n",
    "            secondprefcol_flood_ndvi = secondprefcol_flood.select('NDVI').median()\n",
    "            secondprefcol_flood_evi = secondprefcol_flood.select('EVI').median()\n",
    "            secondprefcol_flood = secondprefcol_flood_lswi.addBands(secondprefcol_flood_ndvi).addBands(secondprefcol_flood_evi)\n",
    "\n",
    "            # Apply masks\n",
    "            secondprefcol_flood_masked = landcovermasking(secondprefcol_flood)\n",
    "\n",
    "            # Add second rice to rice map\n",
    "            secondrice = addRICE(secondprefcol_flood_masked).select('RICE') \n",
    "            secondriceclass = classornot(secondrice).multiply(20)\n",
    "            riceclass = riceclass.add(secondriceclass)\n",
    "\n",
    "\n",
    "\n",
    "        # CONVERT MAP TO BINARY\n",
    "        # If parameter binarymap is 'yes', the map is converted into binary rice map\n",
    "        if (binarymap == 'yes'):\n",
    "            riceclass = riceclass.gte(0.1) \n",
    "\n",
    "\n",
    "        # MOSAICKING\n",
    "        # Clip image to prefecture\n",
    "        riceclass_clipped = riceclass.clip(prefpolygon)\n",
    "\n",
    "        # Insert map in list\n",
    "        prefmapslist.append(riceclass_clipped)\n",
    "\n",
    "\n",
    "        # END OF PREFECTURES LOOP\n",
    "\n",
    "    # Mosaic all prefectural maps for current loop period\n",
    "    periodricecol = ee.ImageCollection.fromImages(prefmapslist)\n",
    "    periodmosaic = periodricecol.mosaic()\n",
    "\n",
    "\n",
    "    # Store period mosaic in list\n",
    "    periodmapslist.append(periodmosaic)\n",
    "\n",
    "\n",
    "    # FILTERING\n",
    "    # It is possible to apply a spatial filtering (not used if not exported)\n",
    "    periodmosaic_filtered = periodmosaic.reduceNeighborhood(**{   \n",
    "      'reducer': ee.Reducer.mode(),   \n",
    "      'kernel': ee.Kernel.square(1), \n",
    "      })\n",
    "\n",
    "\n",
    "    # EXPORT MAPS\n",
    "    # Exports to drive: edit name\n",
    "    filename = 'tambo_'+list(periods_dict.keys())[list(periods_dict.values()).index(periodcol)]\n",
    "    geemap.ee_export_image_to_drive(periodmosaic, description=filename, folder='GEEexports', region=japan.geometry(), scale=30)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
